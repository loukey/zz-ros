#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLOæ£€æµ‹å™¨æ¨¡å—
ç”¨äºå›¾åƒåˆ†å‰²å’Œç›®æ ‡æ£€æµ‹
"""

from .base import *
import os
from ultralytics import YOLO
import time


class YOLODetector:
    """YOLOåˆ†å‰²æ£€æµ‹å™¨"""
    
    def __init__(self, model_path='yolo11x-seg.pt', device=None):
        """
        åˆå§‹åŒ–YOLOæ£€æµ‹å™¨
        
        Args:
            model_path (str): YOLOæ¨¡å‹è·¯å¾„
            device (str): è®¾å¤‡é€‰æ‹©ï¼ŒNoneä¸ºè‡ªåŠ¨é€‰æ‹©
        """
        self.model_path = model_path
        
        # æ£€æŸ¥GPUå¯ç”¨æ€§
        if device is None:
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        else:
            self.device = device
            
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        if self.device == 'cuda':
            print(f"GPUå‹å·: {torch.cuda.get_device_name(0)}")
            print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        
        # åŠ è½½YOLO11åˆ†å‰²æ¨¡å‹å¹¶æŒ‡å®šè®¾å¤‡
        self.model = YOLO(model_path)
        self.model.to(self.device)
    
    def detect_single_image(self, image_path):
        """
        æ£€æµ‹å•å¼ å›¾åƒ
        
        Args:
            image_path (str): å›¾åƒè·¯å¾„
            
        Returns:
            dict: æ£€æµ‹ç»“æœ
            {
                'image_file': å›¾åƒæ–‡ä»¶å,
                'image_path': å›¾åƒå®Œæ•´è·¯å¾„,
                'original_image': åŸå§‹å›¾åƒæ•°ç»„,
                'detection_results': YOLOæ£€æµ‹ç»“æœ,
                'objects': [
                    {
                        'class_name': ç±»åˆ«åç§°,
                        'confidence': ç½®ä¿¡åº¦,
                        'mask': æ©ç æ•°ç»„,
                        'orientation': æ–¹å‘è§’åº¦,
                        'centroid': è´¨å¿ƒåæ ‡,
                        'direction_vector': æ–¹å‘å‘é‡
                    },
                    ...
                ]
            }
        """
        if not os.path.exists(image_path):
            print(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            return None
        
        img_file = os.path.basename(image_path)
        print(f"æ­£åœ¨å¤„ç†: {img_file}")
        
        # è¯»å–åŸå§‹å›¾åƒ
        original_img = cv2.imread(image_path)
        if original_img is None:
            print(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
            return None
            
        img_height, img_width = original_img.shape[:2]
        
        # ä½¿ç”¨YOLOè¿›è¡Œè¯­ä¹‰åˆ†å‰²
        if self.device == 'cuda':
            with torch.autocast(device_type='cuda'):
                results = self.model(image_path, device=self.device)
        else:
            results = self.model(image_path, device=self.device)
        
        # åˆå§‹åŒ–æ£€æµ‹ç»“æœ
        detection_result = {
            'image_file': img_file,
            'image_path': image_path,
            'original_image': original_img.copy(),
            'detection_results': results,
            'objects': []
        }
        
        # å¤„ç†åˆ†å‰²ç»“æœ
        for r in results:
            # è·å–åˆ†å‰²æ©ç 
            if r.masks is not None:
                print(f"  - æ£€æµ‹åˆ° {len(r.masks)} ä¸ªåˆ†å‰²åŒºåŸŸ")
                
                # è·å–æ£€æµ‹æ¡†ä¿¡æ¯
                boxes = r.boxes
                
                if boxes is not None:
                    for i, box in enumerate(boxes):
                        cls = int(box.cls)
                        conf = float(box.conf)
                        original_class_name = self.model.names[cls]
                        
                        print(f"    åŒºåŸŸ {i+1}: {original_class_name} -> part, ç½®ä¿¡åº¦: {conf:.2f}")
                
                # å¤„ç†æ©ç æ•°æ®
                masks = r.masks.data
                
                # æ‰¹é‡å¤„ç†æ©ç ï¼Œå‡å°‘GPU-CPUæ•°æ®ä¼ è¾“
                if self.device == 'cuda':
                    # interpolateçš„sizeå‚æ•°éœ€è¦æ˜¯(height, width)æ ¼å¼
                    target_size = (original_img.shape[0], original_img.shape[1])
                    masks_resized = torch.nn.functional.interpolate(
                        masks.unsqueeze(1).float(), 
                        size=target_size, 
                        mode='bilinear', 
                        align_corners=False
                    ).squeeze(1)
                    masks_cpu = masks_resized.cpu().numpy()
                else:
                    masks_cpu = masks.cpu().numpy()
                
                for i, mask in enumerate(masks_cpu):
                    if self.device != 'cuda':
                        # cv2.resizeçš„å‚æ•°æ˜¯(width, height)æ ¼å¼
                        mask_resized = cv2.resize(mask, 
                                                (original_img.shape[1], original_img.shape[0]))
                    else:
                        mask_resized = mask
                        
                    mask_bool = mask_resized > 0.5
                    
                    # ç¡®ä¿mask_boolçš„å½¢çŠ¶ä¸åŸå›¾åƒå…¼å®¹
                    if mask_bool.shape != original_img.shape[:2]:
                        print(f"è­¦å‘Šï¼šæ©ç å°ºå¯¸ä¸åŒ¹é…ï¼Œé‡æ–°è°ƒæ•´ - mask: {mask_bool.shape}, img: {original_img.shape[:2]}")
                        mask_bool = cv2.resize(mask_bool.astype(np.uint8), 
                                             (original_img.shape[1], original_img.shape[0])) > 0.5
                    
                    # è®¡ç®—é›¶ä»¶å°–ç«¯æ–¹å‘
                    orientation, centroid, tip_vector = calculate_part_orientation(mask_resized)
                    
                    # å­˜å‚¨å¯¹è±¡ä¿¡æ¯
                    obj_info = {
                        'class_name': 'part',
                        'confidence': float(boxes[i].conf) if boxes is not None and i < len(boxes) else 0.0,
                        'mask': mask_bool.copy(),
                        'orientation': orientation,
                        'centroid': centroid,
                        'tip_vector': tip_vector
                    }
                    detection_result['objects'].append(obj_info)
                    
                    if orientation is not None:
                        print(f"      é›¶ä»¶å°–ç«¯æ–¹å‘: {orientation:.1f}åº¦")
                
                # æ¸…ç†GPUå†…å­˜
                if self.device == 'cuda':
                    torch.cuda.empty_cache()
                    
            else:
                print("  - æœªæ£€æµ‹åˆ°åˆ†å‰²åŒºåŸŸ")
        
        # å¤„ç†å®Œä¸€å¼ å›¾ç‰‡åæ¸…ç†GPUå†…å­˜
        if self.device == 'cuda':
            torch.cuda.empty_cache()
            
        return detection_result
    
    def detect_batch_images(self, images_dir='./data/images'):
        """
        æ‰¹é‡å¤„ç†å›¾åƒåˆ†å‰²å’Œæ–¹å‘è¯†åˆ«
        
        Args:
            images_dir (str): è¾“å…¥å›¾åƒç›®å½•è·¯å¾„
            
        Returns:
            list: æ‰€æœ‰å›¾åƒçš„å¤„ç†ç»“æœåˆ—è¡¨
        """
        start_time = time.time()
        
        # æ£€æŸ¥å›¾åƒç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(images_dir):
            print(f"å›¾åƒç›®å½• {images_dir} ä¸å­˜åœ¨")
            return []
        
        # è·å–æ‰€æœ‰jpgå›¾åƒæ–‡ä»¶
        image_files = [f for f in os.listdir(images_dir) if f.lower().endswith('.jpg')]
        
        if not image_files:
            print("åœ¨imagesç›®å½•ä¸­æœªæ‰¾åˆ°jpgå›¾åƒæ–‡ä»¶")
            return []
        
        print(f"æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶ï¼Œå¼€å§‹è¿›è¡Œè¯­ä¹‰åˆ†å‰²æ£€æµ‹...")
        
        # å­˜å‚¨æ‰€æœ‰å¤„ç†ç»“æœ
        all_results = []
        
        # æ‰¹é‡å¤„ç†å›¾åƒ
        for img_file in image_files:
            img_path = os.path.join(images_dir, img_file)
            result = self.detect_single_image(img_path)
            if result:
                all_results.append(result)
        
        # å¤„ç†å®Œæˆç»Ÿè®¡
        total_time = time.time() - start_time
        total_objects = sum(len(result['objects']) for result in all_results)
        total_orientations = sum(1 for result in all_results for obj in result['objects'] if obj['orientation'] is not None)
        
        print(f"\n=== è¯­ä¹‰åˆ†å‰²å’Œæ–¹å‘è¯†åˆ«å®Œæˆ ===")
        print(f"å¤„ç†äº† {len(all_results)} å¼ å›¾åƒ")
        print(f"æ£€æµ‹åˆ° {total_objects} ä¸ªç›®æ ‡å¯¹è±¡")
        print(f"è®¡ç®—äº† {total_orientations} ä¸ªæ–¹å‘è§’åº¦")
        print(f"æ€»ç”¨æ—¶: {total_time:.2f}ç§’")
        
        return all_results
    
    def save_results(self, results, results_dir='./data/images/result'):
        """
        ä¿å­˜è¯†åˆ«ç»“æœåˆ°æ–‡ä»¶ï¼Œå¹¶è¿›è¡Œæ‰€æœ‰çš„å¯è§†åŒ–å·¥ä½œ
        
        Args:
            results (list): æ£€æµ‹ç»“æœåˆ—è¡¨
            results_dir (str): ç»“æœä¿å­˜ç›®å½•
        """
        if not results:
            print("æ²¡æœ‰ç»“æœéœ€è¦ä¿å­˜")
            return
        
        # åˆ›å»ºç»“æœç›®å½•
        os.makedirs(results_dir, exist_ok=True)
        
        print(f"\nå¼€å§‹ç”Ÿæˆå¯è§†åŒ–å›¾åƒå¹¶ä¿å­˜ç»“æœåˆ°: {results_dir}")
        
        # å®šä¹‰é¢œè‰²åˆ—è¡¨
        colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), 
                  (255, 0, 255), (0, 255, 255), (128, 0, 128), (255, 165, 0)]
        
        for result in results:
            img_file = result['image_file']
            original_img = result['original_image']
            objects = result['objects']
            detection_results = result['detection_results']
            
            print(f"æ­£åœ¨ç”Ÿæˆ {img_file} çš„å¯è§†åŒ–å›¾åƒ...")
            
            # 1. ç”Ÿæˆåˆ†å‰²ç»“æœå›¾åƒ
            if objects:
                colored_mask = np.zeros_like(original_img)
                
                for i, obj in enumerate(objects):
                    mask_bool = obj['mask']
                    color = colors[i % len(colors)]
                    colored_mask[mask_bool] = color
                
                # æ··åˆåŸå›¾å’Œå½©è‰²æ©ç 
                segmented_image = cv2.addWeighted(original_img, 0.7, colored_mask, 0.3, 0)
                
                # ä¿å­˜åˆ†å‰²ç»“æœ
                mask_output_path = os.path.join(results_dir, f'segmented_{img_file}')
                cv2.imwrite(mask_output_path, segmented_image)
                print(f"  - åˆ†å‰²ç»“æœå·²ä¿å­˜åˆ°: {mask_output_path}")
            
            # 2. ç”Ÿæˆæ–¹å‘å¯è§†åŒ–å›¾åƒ
            if objects:
                orientation_img = original_img.copy()
                
                for obj in objects:
                    if obj['orientation'] is not None:
                        orientation_img = draw_orientation_arrow(
                            orientation_img, 
                            obj['centroid'], 
                            obj['tip_vector'], 
                            obj['orientation']
                        )
                
                # ä¿å­˜æ–¹å‘å¯è§†åŒ–ç»“æœ
                orientation_output_path = os.path.join(results_dir, f'orientation_{img_file}')
                cv2.imwrite(orientation_output_path, orientation_img)
                print(f"  - æ–¹å‘ç»“æœå·²ä¿å­˜åˆ°: {orientation_output_path}")
            
            # 3. ç”Ÿæˆå®Œæ•´æ£€æµ‹æ ‡æ³¨å›¾åƒ
            if detection_results:
                annotated_image = detection_results[0].plot()
                
                # ä¿å­˜å®Œæ•´æ£€æµ‹ç»“æœ
                output_path = os.path.join(results_dir, f'detected_{img_file}')
                cv2.imwrite(output_path, annotated_image)
                print(f"  - å®Œæ•´ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        
        print("æ‰€æœ‰å¯è§†åŒ–å›¾åƒç”Ÿæˆå’Œä¿å­˜å®Œæˆ")
    
    def process_and_save(self, images_dir='./data/images/origin_img', results_dir='./data/images/result'):
        """
        å®Œæ•´çš„æ£€æµ‹å’Œä¿å­˜æµç¨‹
        
        Args:
            images_dir (str): è¾“å…¥å›¾åƒç›®å½•
            results_dir (str): ç»“æœä¿å­˜ç›®å½•
        """
        # æ‰§è¡Œæ£€æµ‹
        results = self.detect_batch_images(images_dir)
        
        if results:
            # ä¿å­˜ç»“æœ
            self.save_results(results, results_dir)
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            total_objects = sum(len(result['objects']) for result in results)
            total_orientations = sum(1 for result in results for obj in result['objects'] if obj['orientation'] is not None)
            
            print(f"\n=== å¤„ç†å®Œæˆ ===")
            print(f"âœ… å¤„ç†å›¾åƒ: {len(results)} å¼ ")
            print(f"âœ… æ£€æµ‹å¯¹è±¡: {total_objects} ä¸ª")
            print(f"âœ… è®¡ç®—æ–¹å‘: {total_orientations} ä¸ª")
            
            # æ˜¾ç¤ºæ¯å¼ å›¾åƒçš„è¯¦ç»†ç»“æœ
            print(f"\nğŸ“Š è¯¦ç»†ç»“æœ:")
            for i, result in enumerate(results, 1):
                print(f"  {i}. {result['image_file']}: {len(result['objects'])} ä¸ªå¯¹è±¡")
                for j, obj in enumerate(result['objects'], 1):
                    if obj['orientation'] is not None:
                        print(f"     å¯¹è±¡{j}: æ–¹å‘ {obj['orientation']:.1f}åº¦, ç½®ä¿¡åº¦ {obj['confidence']:.2f}")
                    else:
                        print(f"     å¯¹è±¡{j}: æ–¹å‘è®¡ç®—å¤±è´¥, ç½®ä¿¡åº¦ {obj['confidence']:.2f}")
        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯å¤„ç†çš„å›¾åƒæˆ–å¤„ç†å¤±è´¥")
        
        return results

