#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLO OBB è®­ç»ƒæ•°æ®ç”Ÿæˆå™¨
ä»åˆ†å‰²æ¨¡å‹ç»“æœç”Ÿæˆæ—‹è½¬è¾¹ç•Œæ¡†(OBB)è®­ç»ƒæ•°æ®
åŸºäºPCAæ–¹æ³•è®¡ç®—é›¶ä»¶çš„ä¸­å¿ƒç‚¹å’Œæ–¹å‘
"""

import os
import sys
import cv2
import numpy as np
import yaml
import random
from pathlib import Path
import torch
from sklearn.decomposition import PCA
from ultralytics import YOLO
import time
from datetime import datetime

# ç›´æ¥å®ç°æ‰€éœ€çš„å‡½æ•°ï¼Œé¿å…å¯¼å…¥é—®é¢˜
def calculate_extension_distance(mask, start_point, direction_vector, width, height):
    """
    è®¡ç®—ä»èµ·å§‹ç‚¹æ²¿æŒ‡å®šæ–¹å‘èƒ½åœ¨æ©ç å†…å»¶ä¼¸çš„æœ€å¤§è·ç¦»
    """
    # æ ‡å‡†åŒ–æ–¹å‘å‘é‡
    direction_vector = direction_vector / np.linalg.norm(direction_vector)
    
    max_distance = 0
    step_size = 0.5
    
    # é€æ­¥å»¶ä¼¸ç›´åˆ°ç¦»å¼€æ©ç è¾¹ç•Œ
    for step in range(1, int(max(width, height) * 2)):
        # è®¡ç®—å½“å‰ç‚¹
        current_point = start_point + step * step_size * direction_vector
        
        # æ£€æŸ¥è¾¹ç•Œ
        x, y = int(round(current_point[0])), int(round(current_point[1]))
        if x < 0 or x >= width or y < 0 or y >= height:
            break
        
        # æ£€æŸ¥æ˜¯å¦ä»åœ¨æ©ç å†…
        if mask[y, x] > 0.5:
            max_distance = step * step_size
        else:
            break
    
    return max_distance


def calculate_part_orientation(mask):
    """
    æ£€æµ‹é›¶ä»¶å°–ç«¯æ–¹å‘
    è§’åº¦ç³»ç»Ÿï¼šå°–ç«¯å‘ä¸Šä¸º0åº¦ï¼Œé¡ºæ—¶é’ˆä¸ºæ­£è§’åº¦
    è¿”å›: (è§’åº¦, è´¨å¿ƒ, å°–ç«¯å‘é‡)
    """
    if torch.is_tensor(mask):
        mask_np = mask.cpu().numpy()
    else:
        mask_np = mask
    
    # è·å–æ©ç çš„åƒç´ åæ ‡
    y_coords, x_coords = np.where(mask_np > 0.5)
    
    if len(x_coords) < 10:
        return None, None, None
    
    # æ„é€ åæ ‡ç‚¹çŸ©é˜µ
    points = np.column_stack((x_coords, y_coords))
    
    # è®¡ç®—è´¨å¿ƒ
    centroid = np.mean(points, axis=0)
    
    # ä½¿ç”¨PCAè®¡ç®—ä¸»è½´æ–¹å‘
    pca = PCA(n_components=2)
    pca.fit(points)
    principal_vector = pca.components_[0]
    
    # è®¡ç®—æ²¿ä¸»è½´æ­£è´Ÿæ–¹å‘çš„å»¶ä¼¸è·ç¦»
    mask_height, mask_width = mask_np.shape
    
    # æ­£æ–¹å‘å»¶ä¼¸è·ç¦»
    positive_distance = calculate_extension_distance(
        mask_np, centroid, principal_vector, mask_width, mask_height
    )
    
    # è´Ÿæ–¹å‘å»¶ä¼¸è·ç¦»
    negative_distance = calculate_extension_distance(
        mask_np, centroid, -principal_vector, mask_width, mask_height
    )
    
    # å°–ç«¯åœ¨å»¶ä¼¸æ›´è¿œçš„æ–¹å‘
    if positive_distance > negative_distance:
        tip_vector = principal_vector
    else:
        tip_vector = -principal_vector
    
    # è®¡ç®—å°–ç«¯æ–¹å‘è§’åº¦ï¼ˆä»æ­£yè½´å‘ä¸Šå¼€å§‹ï¼Œé¡ºæ—¶é’ˆä¸ºæ­£ï¼‰
    # tip_vector[0] = xåˆ†é‡, tip_vector[1] = yåˆ†é‡
    # æ³¨æ„ï¼šå›¾åƒåæ ‡ç³»ä¸­yè½´å‘ä¸‹ï¼Œæ‰€ä»¥éœ€è¦å–è´Ÿå·
    angle_to_up = np.degrees(np.arctan2(tip_vector[0], -tip_vector[1]))
    
    # æ ‡å‡†åŒ–è§’åº¦åˆ°[-180, 180]èŒƒå›´
    while angle_to_up > 180:
        angle_to_up -= 360
    while angle_to_up <= -180:
        angle_to_up += 360
    
    return angle_to_up, centroid, tip_vector


class YOLOOBBDataGenerator:
    """YOLO OBBæ•°æ®ç”Ÿæˆå™¨"""
    
    def __init__(self, 
                 seg_model_path='../models_cache/yolo_seg_n.pt',
                 images_dir='../data/yolo_dataset/images',
                 output_dir='../data/yolo_obb_dataset',
                 device=None):
        """
        åˆå§‹åŒ–OBBæ•°æ®ç”Ÿæˆå™¨
        
        Args:
            seg_model_path: åˆ†å‰²æ¨¡å‹è·¯å¾„
            images_dir: è¾“å…¥å›¾åƒç›®å½•
            output_dir: è¾“å‡ºæ•°æ®é›†ç›®å½•
            device: è®¾å¤‡é€‰æ‹©
        """
        self.seg_model_path = seg_model_path
        self.images_dir = images_dir
        self.output_dir = output_dir
        
        # è®¾å¤‡é€‰æ‹©
        if device is None:
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        else:
            self.device = device
            
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.images_output_dir = os.path.join(output_dir, 'images')
        self.labels_output_dir = os.path.join(output_dir, 'labels')
        os.makedirs(self.images_output_dir, exist_ok=True)
        os.makedirs(self.labels_output_dir, exist_ok=True)
        
        # åŠ è½½åˆ†å‰²æ¨¡å‹
        self.load_segmentation_model()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_images = 0
        self.total_objects = 0
        self.successful_obb = 0
    
    def load_segmentation_model(self):
        """åŠ è½½åˆ†å‰²æ¨¡å‹"""
        try:
            self.seg_model = YOLO(self.seg_model_path)
            self.seg_model.to(self.device)
            print(f"âœ“ åˆ†å‰²æ¨¡å‹åŠ è½½æˆåŠŸ: {self.seg_model_path}")
        except Exception as e:
            raise RuntimeError(f"åˆ†å‰²æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    def get_mask_from_segmentation(self, image_path):
        """
        ä»åˆ†å‰²æ¨¡å‹è·å–mask
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            
        Returns:
            tuple: (åŸå›¾åƒ, maskåˆ—è¡¨)
        """
        # è¯»å–åŸå§‹å›¾åƒ
        image = cv2.imread(image_path)
        if image is None:
            print(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
            return None, []
        
        # ä½¿ç”¨åˆ†å‰²æ¨¡å‹è¿›è¡Œé¢„æµ‹
        try:
            if self.device == 'cuda':
                with torch.autocast(device_type='cuda'):
                    results = self.seg_model(image_path, device=self.device)
            else:
                results = self.seg_model(image_path, device=self.device)
        except Exception as e:
            print(f"åˆ†å‰²é¢„æµ‹å¤±è´¥: {e}")
            return image, []
        
        masks = []
        img_height, img_width = image.shape[:2]
        
        # å¤„ç†åˆ†å‰²ç»“æœ
        for r in results:
            if r.masks is not None:
                # è·å–æ©ç æ•°æ®
                masks_data = r.masks.data
                
                # æ‰¹é‡å¤„ç†æ©ç 
                if self.device == 'cuda':
                    target_size = (img_height, img_width)
                    masks_resized = torch.nn.functional.interpolate(
                        masks_data.unsqueeze(1).float(), 
                        size=target_size, 
                        mode='bilinear', 
                        align_corners=False
                    ).squeeze(1)
                    masks_cpu = masks_resized.cpu().numpy()
                else:
                    masks_cpu = masks_data.cpu().numpy()
                
                # å¤„ç†æ¯ä¸ªmask
                for mask in masks_cpu:
                    if self.device != 'cuda':
                        mask_resized = cv2.resize(mask, (img_width, img_height))
                    else:
                        mask_resized = mask
                    
                    # è½¬æ¢ä¸ºå¸ƒå°”mask
                    mask_bool = mask_resized > 0.5
                    
                    # ç¡®ä¿maskå°ºå¯¸æ­£ç¡®
                    if mask_bool.shape != (img_height, img_width):
                        mask_bool = cv2.resize(mask_bool.astype(np.uint8), 
                                             (img_width, img_height)) > 0.5
                    
                    masks.append(mask_bool)
        
        # æ¸…ç†GPUå†…å­˜
        if self.device == 'cuda':
            torch.cuda.empty_cache()
        
        return image, masks
    
    def calculate_obb_from_mask(self, mask):
        """
        ä»maskè®¡ç®—OBBå‚æ•°
        åŸºäºPCAå°–ç«¯æ–¹å‘å’Œmaskçš„ç²¾ç¡®æŠ•å½±è®¡ç®—
        
        Args:
            mask: å¸ƒå°”maskæ•°ç»„
            
        Returns:
            dict: OBBå‚æ•° {'center_x', 'center_y', 'width', 'height', 'angle'}
        """
        # ä½¿ç”¨PCAè®¡ç®—æ–¹å‘å’Œè´¨å¿ƒ
        angle, centroid, tip_vector = calculate_part_orientation(mask)
        
        if angle is None or centroid is None or tip_vector is None:
            return None
        
        # è·å–maskçš„åƒç´ åæ ‡
        y_coords, x_coords = np.where(mask > 0.5)
        
        if len(x_coords) < 3:
            return None
        
        # æ„é€ åæ ‡ç‚¹çŸ©é˜µ
        points = np.column_stack((x_coords, y_coords))
        
        # ä½¿ç”¨å·²è®¡ç®—å¥½çš„tip_vectorä½œä¸ºä¸»è½´æ–¹å‘ï¼ˆå°–ç«¯æ–¹å‘ï¼‰
        principal_axis = tip_vector / np.linalg.norm(tip_vector)  # æ ‡å‡†åŒ–
        
        # è®¡ç®—å‚ç›´è½´ï¼ˆæ¬¡è½´ï¼‰- å‚ç›´äºå°–ç«¯æ–¹å‘
        secondary_axis = np.array([-principal_axis[1], principal_axis[0]])  # é€†æ—¶é’ˆæ—‹è½¬90åº¦
        
        # å°†åæ ‡è½¬æ¢åˆ°å±€éƒ¨åæ ‡ç³»ï¼ˆç›¸å¯¹äºè´¨å¿ƒï¼‰
        centered_points = points - centroid
        
        # æŠ•å½±åˆ°ä¸»è½´å’Œæ¬¡è½´
        proj_principal = np.dot(centered_points, principal_axis)  # æ²¿å°–ç«¯æ–¹å‘çš„æŠ•å½±
        proj_secondary = np.dot(centered_points, secondary_axis)  # æ²¿å‚ç›´æ–¹å‘çš„æŠ•å½±
        
        # æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„æ–¹å¼è®¡ç®—OBBå°ºå¯¸ï¼š
        # 1. æ²¿ç€PCAå°–ç«¯æ–¹å‘ï¼Œæ‰¾åˆ°maskçš„æœ€è¿œæŠ•å½±ç‚¹
        max_proj_principal = np.max(proj_principal)
        min_proj_principal = np.min(proj_principal)
        
        # 2. æ²¿ç€PCAå°–ç«¯æ–¹å‘çš„å‚ç›´æ–¹å‘ï¼Œæ‰¾åˆ°maskçš„æœ€è¿œæŠ•å½±ç‚¹
        max_proj_secondary = np.max(proj_secondary)
        min_proj_secondary = np.min(proj_secondary)
        
        # è®¡ç®—OBBçš„å®½åº¦å’Œé«˜åº¦
        # ä¸»è½´æ–¹å‘ï¼ˆå°–ç«¯æ–¹å‘ï¼‰ä¸Šçš„æœ€å¤§æŠ•å½±èŒƒå›´
        obb_length = max_proj_principal - min_proj_principal
        # æ¬¡è½´æ–¹å‘ï¼ˆå‚ç›´æ–¹å‘ï¼‰ä¸Šçš„æœ€å¤§æŠ•å½±èŒƒå›´
        obb_width = max_proj_secondary - min_proj_secondary
        
        # è®¡ç®—OBBçš„çœŸå®ä¸­å¿ƒç‚¹
        # æ²¿ä¸»è½´æ–¹å‘å¾—åˆ°ä¸¤ç«¯æœ€è¿œæŠ•å½±çš„ä¸­ç‚¹ä½œä¸ºä¸­å¿ƒç‚¹
        center_proj_principal = (max_proj_principal + min_proj_principal) / 2
        center_proj_secondary = (max_proj_secondary + min_proj_secondary) / 2
        
        # å°†æŠ•å½±ä¸­å¿ƒè½¬æ¢å›å›¾åƒåæ ‡ç³»
        obb_center = centroid + center_proj_principal * principal_axis + center_proj_secondary * secondary_axis
        
        # ç›´æ¥ä½¿ç”¨PCAè®¡ç®—çš„çœŸå®è§’åº¦ï¼ˆåŒ…å«æ–¹å‘ä¿¡æ¯ï¼‰
        # angleå·²ç»åŒ…å«äº†æ­£ç¡®çš„æ–¹å‘ä¿¡æ¯ï¼šæœä¸Šæ˜¯0Â°ï¼Œé€†æ—¶é’ˆæ˜¯è´Ÿï¼Œé¡ºæ—¶é’ˆæ˜¯æ­£
        obb_angle_deg = angle
        obb_angle_rad = np.radians(angle)
        
        return {
            'center_x': float(obb_center[0]),
            'center_y': float(obb_center[1]),
            'width': float(obb_length),    # ä¸»è½´æ–¹å‘ï¼ˆå°–ç«¯æ–¹å‘ï¼‰çš„é•¿åº¦
            'height': float(obb_width),    # æ¬¡è½´æ–¹å‘ï¼ˆå‚ç›´æ–¹å‘ï¼‰çš„å®½åº¦
            'angle': float(obb_angle_rad),
            'angle_deg': float(obb_angle_deg),
            'principal_axis': principal_axis,  # ä¿å­˜ä¸»è½´æ–¹å‘ç”¨äºå¯è§†åŒ–
            'secondary_axis': secondary_axis,  # ä¿å­˜æ¬¡è½´æ–¹å‘ç”¨äºå¯è§†åŒ–
            'projection_info': {  # è°ƒè¯•ä¿¡æ¯
                'max_principal': float(max_proj_principal),
                'min_principal': float(min_proj_principal),
                'max_secondary': float(max_proj_secondary),
                'min_secondary': float(min_proj_secondary),
                'centroid': centroid.tolist(),
                'obb_center': obb_center.tolist()
            }
        }
    
    def normalize_obb(self, obb_params, img_width, img_height):
        """
        å°†OBBå‚æ•°å½’ä¸€åŒ–åˆ°[0,1]èŒƒå›´
        
        Args:
            obb_params: OBBå‚æ•°å­—å…¸
            img_width: å›¾åƒå®½åº¦
            img_height: å›¾åƒé«˜åº¦
            
        Returns:
            dict: å½’ä¸€åŒ–åçš„OBBå‚æ•°
        """
        normalized = {
            'center_x': obb_params['center_x'] / img_width,
            'center_y': obb_params['center_y'] / img_height,
            'width': obb_params['width'] / img_width,
            'height': obb_params['height'] / img_height,
            'angle': obb_params['angle'],  # è§’åº¦ä¸éœ€è¦å½’ä¸€åŒ–
            'angle_deg': obb_params['angle_deg']
        }
        
        # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
        normalized['center_x'] = np.clip(normalized['center_x'], 0.0, 1.0)
        normalized['center_y'] = np.clip(normalized['center_y'], 0.0, 1.0)
        normalized['width'] = np.clip(normalized['width'], 0.0, 1.0)
        normalized['height'] = np.clip(normalized['height'], 0.0, 1.0)
        
        return normalized
    
    def save_obb_data(self, image, obb_list, base_name):
        """
        ä¿å­˜OBBæ•°æ®
        
        Args:
            image: å›¾åƒæ•°ç»„
            obb_list: OBBå‚æ•°åˆ—è¡¨
            base_name: åŸºç¡€æ–‡ä»¶å
            
        Returns:
            tuple: (å›¾åƒæ–‡ä»¶å, æ ‡ç­¾æ–‡ä»¶å)
        """
        # ç”Ÿæˆæ–‡ä»¶å
        img_filename = f"{base_name}.jpg"
        label_filename = f"{base_name}.txt"
        
        img_path = os.path.join(self.images_output_dir, img_filename)
        label_path = os.path.join(self.labels_output_dir, label_filename)
        
        # ä¿å­˜å›¾åƒ
        cv2.imwrite(img_path, image)
        
        # ä¿å­˜æ ‡ç­¾
        img_height, img_width = image.shape[:2]
        
        with open(label_path, 'w') as f:
            for obb in obb_list:
                # å½’ä¸€åŒ–OBBå‚æ•°
                normalized_obb = self.normalize_obb(obb, img_width, img_height)
                
                # å…ˆåœ¨åƒç´ åæ ‡ç³»ä¸­è®¡ç®—è§’ç‚¹ï¼Œç„¶åå†å½’ä¸€åŒ–
                center_x_px, center_y_px = obb['center_x'], obb['center_y']  # åƒç´ åæ ‡
                width_px, height_px = obb['width'], obb['height']  # åƒç´ å°ºå¯¸
                
                # ç›´æ¥ä½¿ç”¨ä¸»è½´å’Œæ¬¡è½´æ–¹å‘æ¥è®¡ç®—è§’ç‚¹ï¼ˆé¿å…è§’åº¦è½¬æ¢çš„è¯¯å·®ï¼‰
                principal_axis = obb['principal_axis']  # ä¸»è½´æ–¹å‘ï¼ˆå°–ç«¯æ–¹å‘ï¼‰
                secondary_axis = obb['secondary_axis']  # æ¬¡è½´æ–¹å‘ï¼ˆå‚ç›´æ–¹å‘ï¼‰
                
                # è®¡ç®—å››ä¸ªè§’ç‚¹ç›¸å¯¹äºä¸­å¿ƒç‚¹çš„ä½ç½®
                # ä½¿ç”¨ä¸»è½´å’Œæ¬¡è½´æ–¹å‘ç›´æ¥è®¡ç®—ï¼Œç¡®ä¿OBBä¸è½´æ–¹å‘å®Œå…¨å¯¹é½
                half_width = width_px / 2   # ä¸»è½´æ–¹å‘çš„ä¸€åŠé•¿åº¦
                half_height = height_px / 2  # æ¬¡è½´æ–¹å‘çš„ä¸€åŠé•¿åº¦
                
                # å››ä¸ªè§’ç‚¹åœ¨ä¸»è½´/æ¬¡è½´åæ ‡ç³»ä¸­çš„ä½ç½®
                corners_in_local = [
                    (-half_width, -half_height),  # å·¦ä¸‹
                    (half_width, -half_height),   # å³ä¸‹
                    (half_width, half_height),    # å³ä¸Š
                    (-half_width, half_height)    # å·¦ä¸Š
                ]
                
                # è½¬æ¢åˆ°å›¾åƒåæ ‡ç³»
                rotated_corners_px = []
                for local_x, local_y in corners_in_local:
                    # ä½¿ç”¨ä¸»è½´å’Œæ¬¡è½´æ–¹å‘è®¡ç®—å®é™…åæ ‡
                    # local_xæ²¿ä¸»è½´æ–¹å‘ï¼Œlocal_yæ²¿æ¬¡è½´æ–¹å‘
                    point_vector = local_x * principal_axis + local_y * secondary_axis
                    
                    # è½¬æ¢åˆ°å›¾åƒåæ ‡ç³»ï¼ˆåŠ ä¸Šä¸­å¿ƒç‚¹åæ ‡ï¼‰
                    point_x = center_x_px + point_vector[0]
                    point_y = center_y_px + point_vector[1]
                    rotated_corners_px.append([point_x, point_y])
                
                rotated_corners_px = np.array(rotated_corners_px)
                
                # å½’ä¸€åŒ–è§’ç‚¹åæ ‡
                rotated_corners = rotated_corners_px.copy()
                rotated_corners[:, 0] /= img_width   # å½’ä¸€åŒ–xåæ ‡
                rotated_corners[:, 1] /= img_height  # å½’ä¸€åŒ–yåæ ‡
                
                # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
                rotated_corners = np.clip(rotated_corners, 0.0, 1.0)
                
                # æ‰©å±•YOLO OBBæ ¼å¼: class_id x1 y1 x2 y2 x3 y3 x4 y4 angle
                # å±•å¹³è§’ç‚¹åæ ‡
                coords = rotated_corners.flatten()
                coords_str = ' '.join([f"{coord:.6f}" for coord in coords])
                
                # æ·»åŠ è§’åº¦ä¿¡æ¯ï¼ˆè½¬æ¢ä¸ºåº¦æ•°ï¼‰
                angle_deg = obb['angle_deg']
                
                line = f"0 {coords_str} {angle_deg:.6f}\n"
                f.write(line)
        
        return img_filename, label_filename
    
    def process_single_image(self, image_path):
        """
        å¤„ç†å•å¼ å›¾åƒç”ŸæˆOBBæ•°æ®
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸå¤„ç†
        """
        print(f"æ­£åœ¨å¤„ç†: {os.path.basename(image_path)}")
        
        # ä»åˆ†å‰²æ¨¡å‹è·å–mask
        image, masks = self.get_mask_from_segmentation(image_path)
        
        if image is None or not masks:
            print(f"  - è·³è¿‡: æ— æ³•è·å–æœ‰æ•ˆçš„åˆ†å‰²ç»“æœ")
            return False
        
        print(f"  - æ£€æµ‹åˆ° {len(masks)} ä¸ªå¯¹è±¡")
        
        # è®¡ç®—æ¯ä¸ªmaskçš„OBBå‚æ•°
        obb_list = []
        for i, mask in enumerate(masks):
            obb_params = self.calculate_obb_from_mask(mask)
            if obb_params is not None:
                obb_list.append(obb_params)
                print(f"    å¯¹è±¡ {i+1}: ä¸­å¿ƒ({obb_params['center_x']:.1f}, {obb_params['center_y']:.1f}), "
                      f"å°ºå¯¸({obb_params['width']:.1f}x{obb_params['height']:.1f}), "
                      f"è§’åº¦{obb_params['angle_deg']:.1f}Â°")
                self.successful_obb += 1
            else:
                print(f"    å¯¹è±¡ {i+1}: OBBè®¡ç®—å¤±è´¥")
        
        if not obb_list:
            print(f"  - è·³è¿‡: æ²¡æœ‰æœ‰æ•ˆçš„OBBæ•°æ®")
            return False
        
        # ä¿å­˜OBBæ•°æ®
        base_name = os.path.splitext(os.path.basename(image_path))[0]
        img_filename, label_filename = self.save_obb_data(image, obb_list, base_name)
        
        print(f"  - ä¿å­˜æˆåŠŸ: {img_filename}, {label_filename}")
        self.total_objects += len(obb_list)
        
        return True
    
    def generate_dataset(self):
        """
        ç”Ÿæˆå®Œæ•´çš„OBBæ•°æ®é›†
        
        Returns:
            tuple: (å¤„ç†çš„å›¾åƒæ•°é‡, ç”Ÿæˆçš„OBBæ•°é‡)
        """
        print("å¼€å§‹ç”ŸæˆYOLO OBBè®­ç»ƒæ•°æ®é›†...")
        print("=" * 60)
        
        # æ£€æŸ¥è¾“å…¥ç›®å½•
        if not os.path.exists(self.images_dir):
            print(f"é”™è¯¯: è¾“å…¥ç›®å½•ä¸å­˜åœ¨ {self.images_dir}")
            return 0, 0
        
        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
        image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
            image_files.extend(Path(self.images_dir).glob(ext))
            image_files.extend(Path(self.images_dir).glob(ext.upper()))
        
        if not image_files:
            print(f"é”™è¯¯: åœ¨ {self.images_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            return 0, 0
        
        print(f"æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
        
        # å¤„ç†æ¯ä¸ªå›¾åƒ
        start_time = time.time()
        
        for i, image_path in enumerate(image_files, 1):
            print(f"\n[{i}/{len(image_files)}] ", end="")
            
            if self.process_single_image(str(image_path)):
                self.total_images += 1
        
        # å¤„ç†å®Œæˆç»Ÿè®¡
        total_time = time.time() - start_time
        
        print(f"\n" + "=" * 60)
        print(f"OBBæ•°æ®é›†ç”Ÿæˆå®Œæˆ!")
        print(f"âœ… å¤„ç†å›¾åƒ: {self.total_images}/{len(image_files)}")
        print(f"âœ… ç”Ÿæˆå¯¹è±¡: {self.total_objects}")
        print(f"âœ… æˆåŠŸOBB: {self.successful_obb}")
        print(f"âœ… æ€»ç”¨æ—¶: {total_time:.2f}ç§’")
        print(f"âœ… å¹³å‡æ¯å¼ : {total_time/len(image_files):.2f}ç§’")
        
        # ç”Ÿæˆæ•°æ®é›†é…ç½®æ–‡ä»¶
        self.create_dataset_yaml()
        
        return self.total_images, self.total_objects
    
    def create_dataset_yaml(self):
        """åˆ›å»ºYOLO OBBæ•°æ®é›†é…ç½®æ–‡ä»¶"""
        yaml_content = f"""# YOLO OBB Dataset Configuration
# Generated from segmentation model results using PCA-based orientation
# Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

path: {os.path.abspath(self.output_dir)}
train: images
val: images  # ä½¿ç”¨ç›¸åŒç›®å½•ï¼Œå®é™…ä½¿ç”¨æ—¶åº”è¯¥åˆ†å‰²train/val

# Classes
nc: 1  # number of classes
names: ['part']  # class names

# Dataset info
total_images: {self.total_images}
total_objects: {self.total_objects}
successful_obb: {self.successful_obb}
source_model: {self.seg_model_path}

# Extended OBB format: class_id x1 y1 x2 y2 x3 y3 x4 y4 angle
# 8 coordinates representing 4 corners of oriented bounding box + angle in degrees
# Coordinates are normalized to [0,1]
# Corner order: left-bottom, right-bottom, right-top, left-top
# Angle in degrees: 0Â° = tip pointing up, positive = clockwise, negative = counterclockwise
# Range: [-180Â°, 180Â°]

# Angle Information:
# Explicit angle value is saved as the 10th parameter
# Generated using PCA-based tip direction detection
# This enables training models that predict both OBB corners and explicit angle

# Training Command:
# yolo obb train data={os.path.abspath(self.output_dir)}/dataset.yaml model=yolo11n-obb.pt epochs=100
# Or use custom config: model=detection_models/configs/yolo_obb_model.yaml
"""
        
        yaml_path = os.path.join(self.output_dir, "dataset.yaml")
        with open(yaml_path, 'w', encoding='utf-8') as f:
            f.write(yaml_content)
        
        print(f"âœ… æ•°æ®é›†é…ç½®æ–‡ä»¶å·²ä¿å­˜: {yaml_path}")
    
    def visualize_obb(self, image_path, save_path=None):
        """
        å¯è§†åŒ–OBBç»“æœ
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            save_path: ä¿å­˜è·¯å¾„
        """
        image, masks = self.get_mask_from_segmentation(image_path)
        
        if image is None or not masks:
            print("æ— æ³•è·å–æœ‰æ•ˆçš„åˆ†å‰²ç»“æœ")
            return
        
        vis_image = image.copy()
        
        for i, mask in enumerate(masks):
            obb_params = self.calculate_obb_from_mask(mask)
            if obb_params is None:
                continue
            
            # ç»˜åˆ¶OBB
            center_x, center_y = obb_params['center_x'], obb_params['center_y']
            width, height = obb_params['width'], obb_params['height']
            principal_axis = obb_params['principal_axis']
            secondary_axis = obb_params['secondary_axis']
            
            # ç›´æ¥ä½¿ç”¨ä¸»è½´å’Œæ¬¡è½´æ–¹å‘æ¥è®¡ç®—è§’ç‚¹ï¼ˆä¸ä¿å­˜æ ‡ç­¾é€»è¾‘ä¸€è‡´ï¼‰
            # è®¡ç®—å››ä¸ªè§’ç‚¹ç›¸å¯¹äºä¸­å¿ƒç‚¹çš„ä½ç½®
            # ä½¿ç”¨ä¸»è½´å’Œæ¬¡è½´æ–¹å‘ç›´æ¥è®¡ç®—ï¼Œç¡®ä¿OBBä¸è½´æ–¹å‘å®Œå…¨å¯¹é½
            half_width = width / 2   # ä¸»è½´æ–¹å‘çš„ä¸€åŠé•¿åº¦
            half_height = height / 2  # æ¬¡è½´æ–¹å‘çš„ä¸€åŠé•¿åº¦
            
            # å››ä¸ªè§’ç‚¹åœ¨ä¸»è½´/æ¬¡è½´åæ ‡ç³»ä¸­çš„ä½ç½®
            corners_in_local = [
                (-half_width, -half_height),  # å·¦ä¸‹
                (half_width, -half_height),   # å³ä¸‹
                (half_width, half_height),    # å³ä¸Š
                (-half_width, half_height)    # å·¦ä¸Š
            ]
            
            # è½¬æ¢åˆ°å›¾åƒåæ ‡ç³»
            rotated_corners = []
            for local_x, local_y in corners_in_local:
                # ä½¿ç”¨ä¸»è½´å’Œæ¬¡è½´æ–¹å‘è®¡ç®—å®é™…åæ ‡
                # local_xæ²¿ä¸»è½´æ–¹å‘ï¼Œlocal_yæ²¿æ¬¡è½´æ–¹å‘
                point_vector = local_x * principal_axis + local_y * secondary_axis
                
                # è½¬æ¢åˆ°å›¾åƒåæ ‡ç³»ï¼ˆåŠ ä¸Šä¸­å¿ƒç‚¹åæ ‡ï¼‰
                point = (center_x + point_vector[0], center_y + point_vector[1])
                rotated_corners.append(point)
            
            rotated_corners = np.array(rotated_corners).astype(np.int32)
            
            # ç»˜åˆ¶OBB
            cv2.polylines(vis_image, [rotated_corners], True, (0, 255, 0), 2)
            
            # ç»˜åˆ¶ä¸­å¿ƒç‚¹
            cv2.circle(vis_image, (int(center_x), int(center_y)), 5, (0, 0, 255), -1)
            
            # ç»˜åˆ¶å°–ç«¯æ–¹å‘ç®­å¤´ï¼ˆæ²¿ä¸»è½´æ–¹å‘ï¼‰
            arrow_length = 50
            # ç›´æ¥ä½¿ç”¨ä¸»è½´æ–¹å‘ç»˜åˆ¶ç®­å¤´ï¼Œç¡®ä¿ä¸OBBæ¡†æ–¹å‘ä¸€è‡´
            arrow_vector = arrow_length * principal_axis
            arrow_end_x = center_x + arrow_vector[0]
            arrow_end_y = center_y + arrow_vector[1]
            cv2.arrowedLine(vis_image, 
                          (int(center_x), int(center_y)), 
                          (int(arrow_end_x), int(arrow_end_y)), 
                          (255, 0, 0), 2, tipLength=0.3)
            
            # æ·»åŠ è§’åº¦æ–‡æœ¬
            angle_text = f"{obb_params['angle_deg']:.1f}Â°"
            cv2.putText(vis_image, angle_text, 
                       (int(center_x) + 10, int(center_y) - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        if save_path:
            cv2.imwrite(save_path, vis_image)
            print(f"å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {save_path}")
        
        return vis_image


def main():
    """ä¸»å‡½æ•°"""
    print("YOLO OBB è®­ç»ƒæ•°æ®ç”Ÿæˆå™¨")
    print("åŸºäºPCAæ–¹æ³•è®¡ç®—é›¶ä»¶æ–¹å‘å’Œè¾¹ç•Œæ¡†")
    print("æ‰©å±•æ ¼å¼ï¼šOBBè§’ç‚¹ + æ˜¾å¼è§’åº¦ä¿¡æ¯ï¼ˆç”¨äºè®­ç»ƒOBB+è§’åº¦é¢„æµ‹æ¨¡å‹ï¼‰")
    print("=" * 60)
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = YOLOOBBDataGenerator(
        seg_model_path='../models_cache/yolo_seg_n.pt',
        images_dir='../data/yolo_dataset/images',
        output_dir='../data/yolo_obb_dataset'
    )
    
    # ç”Ÿæˆæ•°æ®é›†
    total_images, total_objects = generator.generate_dataset()
    
    if total_images > 0:
        print(f"\nğŸ‰ æ•°æ®é›†ç”ŸæˆæˆåŠŸ!")
        print(f"âœ… æ‰©å±•OBBæ ¼å¼ï¼š8ä¸ªè§’ç‚¹åæ ‡ + 1ä¸ªè§’åº¦å€¼")
        print(f"âœ… è§’åº¦ä¿¡æ¯ï¼š0Â°=å‘ä¸Šï¼Œé¡ºæ—¶é’ˆä¸ºæ­£ï¼ŒèŒƒå›´[-180Â°,180Â°]")
        print(f"âœ… æ”¯æŒè®­ç»ƒOBB+è§’åº¦é¢„æµ‹æ¨¡å‹")
        
        print(f"\nğŸ“‹ è®­ç»ƒå‘½ä»¤:")
        print(f"æ ‡å‡†è®­ç»ƒ:")
        print(f"  yolo obb train data=../data/yolo_obb_dataset/dataset.yaml model=yolo11n-obb.pt epochs=100")
        print(f"ä½¿ç”¨è‡ªå®šä¹‰é…ç½®:")
        print(f"  yolo obb train data=../data/yolo_obb_dataset/dataset.yaml model=detection_models/configs/yolo_obb_model.yaml epochs=100")
        
        # å¯è§†åŒ–ä¸€ä¸ªæ ·ä¾‹
        if total_objects > 0:
            import glob
            sample_images = glob.glob('../data/yolo_dataset/images/*.jpg')[:1]
            if sample_images:
                print(f"\nç”Ÿæˆå¯è§†åŒ–æ ·ä¾‹...")
                vis_path = '../data/yolo_obb_dataset/visualization_sample.jpg'
                generator.visualize_obb(sample_images[0], vis_path)
    else:
        print(f"\nâŒ æ•°æ®é›†ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥è¾“å…¥ç›®å½•å’Œæ¨¡å‹è·¯å¾„")


if __name__ == "__main__":
    main()
