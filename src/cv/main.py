import os
import cv2
import numpy as np
import torch
from ultralytics import YOLO
from sklearn.decomposition import PCA
import time


def calculate_part_orientation(mask):
    """
    è®¡ç®—é›¶ä»¶çš„æ–¹å‘è§’åº¦
    ä½¿ç”¨PCAæ–¹æ³•è®¡ç®—ä¸»è½´æ–¹å‘
    """
    # å¦‚æœmaskåœ¨GPUä¸Šï¼Œå…ˆè½¬ç§»åˆ°CPUè¿›è¡ŒPCAè®¡ç®—
    if torch.is_tensor(mask):
        mask_np = mask.cpu().numpy()
    else:
        mask_np = mask
    
    # è·å–æ©ç çš„åƒç´ åæ ‡
    y_coords, x_coords = np.where(mask_np > 0.5)
    
    if len(x_coords) < 10:  # éœ€è¦è¶³å¤Ÿçš„ç‚¹è¿›è¡ŒPCA
        return None, None, None
    
    # æ„é€ åæ ‡ç‚¹çŸ©é˜µ
    points = np.column_stack((x_coords, y_coords))
    
    # è®¡ç®—è´¨å¿ƒ
    centroid = np.mean(points, axis=0)
    
    # ä½¿ç”¨PCAè®¡ç®—ä¸»æˆåˆ†
    pca = PCA(n_components=2)
    pca.fit(points)
    
    # è·å–ç¬¬ä¸€ä¸»æˆåˆ†(ä¸»è½´æ–¹å‘)
    principal_vector = pca.components_[0]
    
    # è®¡ç®—è§’åº¦(ç›¸å¯¹äºæ°´å¹³è½´)
    angle = np.arctan2(principal_vector[1], principal_vector[0])
    angle_degrees = np.degrees(angle)
    
    # æ ‡å‡†åŒ–è§’åº¦åˆ°[-90, 90]èŒƒå›´
    if angle_degrees > 90:
        angle_degrees -= 180
    elif angle_degrees < -90:
        angle_degrees += 180
    
    return angle_degrees, centroid, principal_vector


def draw_orientation_arrow(image, centroid, direction_vector, angle, length=100):
    """
    åœ¨å›¾åƒä¸Šç»˜åˆ¶æ–¹å‘ç®­å¤´
    """
    if centroid is None:
        return image
    
    # è®¡ç®—ç®­å¤´çš„ç»ˆç‚¹
    end_point = centroid + direction_vector * length
    
    # ç»˜åˆ¶ä¸»è½´çº¿
    cv2.arrowedLine(image, 
                    (int(centroid[0]), int(centroid[1])), 
                    (int(end_point[0]), int(end_point[1])), 
                    (0, 255, 255), 3, tipLength=0.3)
    
    # æ·»åŠ è§’åº¦æ–‡å­—
    text_pos = (int(centroid[0] + 10), int(centroid[1] - 10))
    cv2.putText(image, f'{angle:.1f}deg', text_pos, 
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
    
    return image


def process_image_segmentation_and_orientation(images_dir='./data/images', model_path='yolo11x-seg.pt'):
    """
    å¤„ç†å›¾åƒåˆ†å‰²å’Œæ–¹å‘è¯†åˆ«çš„æ ¸å¿ƒå‡½æ•°
    ä¸“æ³¨äºçº¯ç²¹çš„è®¡ç®—å’Œè¯†åˆ«ï¼Œä¸è¿›è¡Œä»»ä½•å¯è§†åŒ–æ“ä½œ
    
    Args:
        images_dir (str): è¾“å…¥å›¾åƒç›®å½•è·¯å¾„
        model_path (str): YOLOæ¨¡å‹æ–‡ä»¶è·¯å¾„
        
    Returns:
        list: æ¯å¼ å›¾åƒçš„å¤„ç†ç»“æœåˆ—è¡¨
        [
            {
                'image_file': å›¾åƒæ–‡ä»¶å,
                'image_path': å›¾åƒå®Œæ•´è·¯å¾„,
                'original_image': åŸå§‹å›¾åƒæ•°ç»„,
                'detection_results': YOLOæ£€æµ‹ç»“æœ,
                'objects': [
                    {
                        'class_name': ç±»åˆ«åç§°,
                        'confidence': ç½®ä¿¡åº¦,
                        'mask': æ©ç æ•°ç»„,
                        'orientation': æ–¹å‘è§’åº¦,
                        'centroid': è´¨å¿ƒåæ ‡,
                        'direction_vector': æ–¹å‘å‘é‡
                    },
                    ...
                ]
            },
            ...
        ]
    """
    start_time = time.time()
    
    # æ£€æŸ¥GPUå¯ç”¨æ€§
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    if device == 'cuda':
        print(f"GPUå‹å·: {torch.cuda.get_device_name(0)}")
        print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # åŠ è½½YOLO11åˆ†å‰²æ¨¡å‹å¹¶æŒ‡å®šGPUè®¾å¤‡
    model = YOLO(model_path)
    model.to(device)  # å°†æ¨¡å‹ç§»åŠ¨åˆ°GPU
    
    # æ£€æŸ¥å›¾åƒç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(images_dir):
        print(f"å›¾åƒç›®å½• {images_dir} ä¸å­˜åœ¨")
        return []
    
    # è·å–æ‰€æœ‰jpgå›¾åƒæ–‡ä»¶
    image_files = [f for f in os.listdir(images_dir) if f.lower().endswith('.jpg')]
    
    if not image_files:
        print("åœ¨imagesç›®å½•ä¸­æœªæ‰¾åˆ°jpgå›¾åƒæ–‡ä»¶")
        return []
    
    print(f"æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶ï¼Œå¼€å§‹è¿›è¡Œè¯­ä¹‰åˆ†å‰²æ£€æµ‹...")
    
    # å­˜å‚¨æ‰€æœ‰å¤„ç†ç»“æœ
    all_results = []
    
    # æ‰¹é‡å¤„ç†å›¾åƒ
    for img_file in image_files:
        img_path = os.path.join(images_dir, img_file)
        print(f"æ­£åœ¨å¤„ç†: {img_file}")
        
        # è¯»å–åŸå§‹å›¾åƒ
        original_img = cv2.imread(img_path)
        img_height, img_width = original_img.shape[:2]
        
        # ä½¿ç”¨YOLOè¿›è¡Œè¯­ä¹‰åˆ†å‰²
        if device == 'cuda':
            with torch.autocast(device_type='cuda'):
                results = model(img_path, device=device)
        else:
            results = model(img_path, device=device)
        
        # åˆå§‹åŒ–å½“å‰å›¾åƒçš„ç»“æœ
        current_result = {
            'image_file': img_file,
            'image_path': img_path,
            'original_image': original_img.copy(),
            'detection_results': results,
            'objects': []
        }
        
        # å¤„ç†åˆ†å‰²ç»“æœ
        for r in results:
            # è·å–åˆ†å‰²æ©ç 
            if r.masks is not None:
                print(f"  - æ£€æµ‹åˆ° {len(r.masks)} ä¸ªåˆ†å‰²åŒºåŸŸ")
                
                # è·å–æ£€æµ‹æ¡†ä¿¡æ¯
                boxes = r.boxes
                
                if boxes is not None:
                    for i, box in enumerate(boxes):
                        cls = int(box.cls)
                        conf = float(box.conf)
                        original_class_name = model.names[cls]
                        
                        print(f"    åŒºåŸŸ {i+1}: {original_class_name} -> part, ç½®ä¿¡åº¦: {conf:.2f}")
                
                # å¤„ç†æ©ç æ•°æ®
                masks = r.masks.data
                
                # æ‰¹é‡å¤„ç†æ©ç ï¼Œå‡å°‘GPU-CPUæ•°æ®ä¼ è¾“
                if device == 'cuda':
                    # interpolateçš„sizeå‚æ•°éœ€è¦æ˜¯(height, width)æ ¼å¼
                    target_size = (original_img.shape[0], original_img.shape[1])
                    masks_resized = torch.nn.functional.interpolate(
                        masks.unsqueeze(1).float(), 
                        size=target_size, 
                        mode='bilinear', 
                        align_corners=False
                    ).squeeze(1)
                    masks_cpu = masks_resized.cpu().numpy()
                else:
                    masks_cpu = masks.cpu().numpy()
                
                for i, mask in enumerate(masks_cpu):
                    if device != 'cuda':
                        # cv2.resizeçš„å‚æ•°æ˜¯(width, height)æ ¼å¼
                        mask_resized = cv2.resize(mask, 
                                                (original_img.shape[1], original_img.shape[0]))
                    else:
                        mask_resized = mask
                        
                    mask_bool = mask_resized > 0.5
                    
                    # ç¡®ä¿mask_boolçš„å½¢çŠ¶ä¸åŸå›¾åƒå…¼å®¹
                    if mask_bool.shape != original_img.shape[:2]:
                        print(f"è­¦å‘Šï¼šæ©ç å°ºå¯¸ä¸åŒ¹é…ï¼Œé‡æ–°è°ƒæ•´ - mask: {mask_bool.shape}, img: {original_img.shape[:2]}")
                        mask_bool = cv2.resize(mask_bool.astype(np.uint8), 
                                             (original_img.shape[1], original_img.shape[0])) > 0.5
                    
                    # è®¡ç®—é›¶ä»¶æ–¹å‘
                    orientation, centroid, direction_vector = calculate_part_orientation(mask_resized)
                    
                    # å­˜å‚¨å¯¹è±¡ä¿¡æ¯
                    obj_info = {
                        'class_name': 'part',
                        'confidence': float(boxes[i].conf) if boxes is not None and i < len(boxes) else 0.0,
                        'mask': mask_bool.copy(),
                        'orientation': orientation,
                        'centroid': centroid,
                        'direction_vector': direction_vector
                    }
                    current_result['objects'].append(obj_info)
                    
                    if orientation is not None:
                        print(f"      é›¶ä»¶æ–¹å‘: {orientation:.1f}åº¦")
                
                # æ¸…ç†GPUå†…å­˜
                if device == 'cuda':
                    torch.cuda.empty_cache()
                
            else:
                print("  - æœªæ£€æµ‹åˆ°åˆ†å‰²åŒºåŸŸ")
        
        # å¤„ç†å®Œä¸€å¼ å›¾ç‰‡åæ¸…ç†GPUå†…å­˜
        if device == 'cuda':
            torch.cuda.empty_cache()
        
        all_results.append(current_result)
    
    # å¤„ç†å®Œæˆ
    total_time = time.time() - start_time
    total_objects = sum(len(result['objects']) for result in all_results)
    total_orientations = sum(1 for result in all_results for obj in result['objects'] if obj['orientation'] is not None)
    
    print(f"\n=== è¯­ä¹‰åˆ†å‰²å’Œæ–¹å‘è¯†åˆ«å®Œæˆ ===")
    print(f"å¤„ç†äº† {len(all_results)} å¼ å›¾åƒ")
    print(f"æ£€æµ‹åˆ° {total_objects} ä¸ªç›®æ ‡å¯¹è±¡")
    print(f"è®¡ç®—äº† {total_orientations} ä¸ªæ–¹å‘è§’åº¦")
    print(f"æ€»ç”¨æ—¶: {total_time:.2f}ç§’")
    
    return all_results


def save_results(results, results_dir='./data/images/result'):
    """
    ä¿å­˜è¯†åˆ«ç»“æœåˆ°æ–‡ä»¶ï¼Œå¹¶è¿›è¡Œæ‰€æœ‰çš„å¯è§†åŒ–å·¥ä½œ
    
    Args:
        results (list): process_image_segmentation_and_orientationçš„è¿”å›ç»“æœ
        results_dir (str): ç»“æœä¿å­˜ç›®å½•
    """
    if not results:
        print("æ²¡æœ‰ç»“æœéœ€è¦ä¿å­˜")
        return
    
    # åˆ›å»ºç»“æœç›®å½•
    os.makedirs(results_dir, exist_ok=True)
    
    print(f"\nå¼€å§‹ç”Ÿæˆå¯è§†åŒ–å›¾åƒå¹¶ä¿å­˜ç»“æœåˆ°: {results_dir}")
    
    # å®šä¹‰é¢œè‰²åˆ—è¡¨
    colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), 
              (255, 0, 255), (0, 255, 255), (128, 0, 128), (255, 165, 0)]
    
    for result in results:
        img_file = result['image_file']
        original_img = result['original_image']
        objects = result['objects']
        detection_results = result['detection_results']
        
        print(f"æ­£åœ¨ç”Ÿæˆ {img_file} çš„å¯è§†åŒ–å›¾åƒ...")
        
        # 1. ç”Ÿæˆåˆ†å‰²ç»“æœå›¾åƒ
        if objects:
            colored_mask = np.zeros_like(original_img)
            
            for i, obj in enumerate(objects):
                mask_bool = obj['mask']
                color = colors[i % len(colors)]
                colored_mask[mask_bool] = color
            
            # æ··åˆåŸå›¾å’Œå½©è‰²æ©ç 
            segmented_image = cv2.addWeighted(original_img, 0.7, colored_mask, 0.3, 0)
            
            # ä¿å­˜åˆ†å‰²ç»“æœ
            mask_output_path = os.path.join(results_dir, f'segmented_{img_file}')
            cv2.imwrite(mask_output_path, segmented_image)
            print(f"  - åˆ†å‰²ç»“æœå·²ä¿å­˜åˆ°: {mask_output_path}")
        
        # 2. ç”Ÿæˆæ–¹å‘å¯è§†åŒ–å›¾åƒ
        if objects:
            orientation_img = original_img.copy()
            
            for obj in objects:
                if obj['orientation'] is not None:
                    orientation_img = draw_orientation_arrow(
                        orientation_img, 
                        obj['centroid'], 
                        obj['direction_vector'], 
                        obj['orientation']
                    )
            
            # ä¿å­˜æ–¹å‘å¯è§†åŒ–ç»“æœ
            orientation_output_path = os.path.join(results_dir, f'orientation_{img_file}')
            cv2.imwrite(orientation_output_path, orientation_img)
            print(f"  - æ–¹å‘ç»“æœå·²ä¿å­˜åˆ°: {orientation_output_path}")
        
        # 3. ç”Ÿæˆå®Œæ•´æ£€æµ‹æ ‡æ³¨å›¾åƒ
        if detection_results:
            annotated_image = detection_results[0].plot()
            
            # ä¿å­˜å®Œæ•´æ£€æµ‹ç»“æœ
            output_path = os.path.join(results_dir, f'detected_{img_file}')
            cv2.imwrite(output_path, annotated_image)
            print(f"  - å®Œæ•´ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    
    print("æ‰€æœ‰å¯è§†åŒ–å›¾åƒç”Ÿæˆå’Œä¿å­˜å®Œæˆ")


def main():
    """
    ä¸»å‡½æ•° - æ‰§è¡Œå®Œæ•´çš„è¯†åˆ«å’Œä¿å­˜æµç¨‹
    """
    print("=== è¯­ä¹‰åˆ†å‰²å’Œæ–¹å‘è¯†åˆ«å·¥å…· ===")
    
    # æ‰§è¡Œè¯†åˆ«å¤„ç†
    results = process_image_segmentation_and_orientation()
    
    if results:
        # ä¿å­˜ç»“æœ
        save_results(results)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        total_objects = sum(len(result['objects']) for result in results)
        total_orientations = sum(1 for result in results for obj in result['objects'] if obj['orientation'] is not None)
        
        print(f"\n=== å¤„ç†å®Œæˆ ===")
        print(f"âœ… å¤„ç†å›¾åƒ: {len(results)} å¼ ")
        print(f"âœ… æ£€æµ‹å¯¹è±¡: {total_objects} ä¸ª")
        print(f"âœ… è®¡ç®—æ–¹å‘: {total_orientations} ä¸ª")
        
        # æ˜¾ç¤ºæ¯å¼ å›¾åƒçš„è¯¦ç»†ç»“æœ
        print(f"\nğŸ“Š è¯¦ç»†ç»“æœ:")
        for i, result in enumerate(results, 1):
            print(f"  {i}. {result['image_file']}: {len(result['objects'])} ä¸ªå¯¹è±¡")
            for j, obj in enumerate(result['objects'], 1):
                if obj['orientation'] is not None:
                    print(f"     å¯¹è±¡{j}: æ–¹å‘ {obj['orientation']:.1f}åº¦, ç½®ä¿¡åº¦ {obj['confidence']:.2f}")
                else:
                    print(f"     å¯¹è±¡{j}: æ–¹å‘è®¡ç®—å¤±è´¥, ç½®ä¿¡åº¦ {obj['confidence']:.2f}")
    else:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯å¤„ç†çš„å›¾åƒæˆ–å¤„ç†å¤±è´¥")


if __name__ == "__main__":
    main()
