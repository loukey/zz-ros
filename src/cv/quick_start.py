#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLO11 OBB å¿«é€Ÿå¼€å§‹è„šæœ¬
ä¸€é”®å®Œæˆä»æ•°æ®ç”Ÿæˆåˆ°æ¨¡å‹è®­ç»ƒçš„å®Œæ•´æµç¨‹
"""

import os
import sys
import argparse
import subprocess
from pathlib import Path
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def check_environment():
    """æ£€æŸ¥ç¯å¢ƒä¾èµ–"""
    logger.info("=== æ£€æŸ¥ç¯å¢ƒä¾èµ– ===")
    
    # æ£€æŸ¥æ•°æ®ç›®å½•
    data_dir = Path("data/images")
    if not data_dir.exists():
        logger.error(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        logger.info("è¯·åˆ›å»º data/images/ ç›®å½•å¹¶æ”¾å…¥æ‚¨çš„å›¾åƒæ–‡ä»¶")
        return False
    
    # æ£€æŸ¥å›¾åƒæ–‡ä»¶
    image_files = list(data_dir.glob("*.jpg")) + list(data_dir.glob("*.png"))
    if not image_files:
        logger.error("åœ¨ data/images/ ç›®å½•ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        logger.info("è¯·å°†æ‚¨çš„å›¾åƒæ–‡ä»¶ï¼ˆ.jpgæˆ–.pngï¼‰æ”¾å…¥ data/images/ ç›®å½•")
        return False
    
    logger.info(f"æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
    
    # æ£€æŸ¥èƒŒæ™¯ç›®å½•ï¼ˆå¯é€‰ï¼‰
    background_dir = Path("data/images/background")
    if background_dir.exists():
        bg_files = list(background_dir.glob("*.jpg")) + list(background_dir.glob("*.png"))
        logger.info(f"æ‰¾åˆ° {len(bg_files)} ä¸ªèƒŒæ™¯å›¾åƒ")
    else:
        logger.info("æœªæ‰¾åˆ°èƒŒæ™¯å›¾åƒç›®å½•ï¼Œå°†ä½¿ç”¨é»˜è®¤èƒŒæ™¯")
    
    # æ£€æŸ¥YOLOæ¨¡å‹æ–‡ä»¶
    model_file = Path("yolo11x-seg.pt")
    if not model_file.exists():
        logger.warning("YOLO11åˆ†å‰²æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œé¦–æ¬¡è¿è¡Œæ—¶ä¼šè‡ªåŠ¨ä¸‹è½½")
    
    # æ£€æŸ¥PythonåŒ…
    try:
        import torch
        import cv2
        import numpy as np
        from ultralytics import YOLO
        from sklearn.decomposition import PCA
        logger.info("æ‰€æœ‰å¿…éœ€çš„PythonåŒ…éƒ½å·²å®‰è£…")
    except ImportError as e:
        logger.error(f"ç¼ºå°‘å¿…éœ€çš„PythonåŒ…: {e}")
        logger.info("è¯·è¿è¡Œ: pip install -r detection_models/requirements.txt")
        return False
    
    # æ£€æŸ¥GPU
    try:
        import torch
        if torch.cuda.is_available():
            logger.info(f"æ£€æµ‹åˆ°GPU: {torch.cuda.get_device_name(0)}")
        else:
            logger.warning("æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUï¼ˆè®­ç»ƒé€Ÿåº¦è¾ƒæ…¢ï¼‰")
    except:
        pass
    
    return True


def generate_obb_data():
    """ç”ŸæˆOBBè®­ç»ƒæ•°æ®"""
    logger.info("=== ç”ŸæˆOBBè®­ç»ƒæ•°æ® ===")
    
    try:
        # è¿è¡Œmain.pyç”ŸæˆOBBæ•°æ®
        result = subprocess.run([sys.executable, "main.py"], 
                              capture_output=True, text=True, encoding='utf-8', errors='ignore')
        
        if result.returncode != 0:
            logger.error(f"æ•°æ®ç”Ÿæˆå¤±è´¥: {result.stderr}")
            return False
        
        logger.info("OBBè®­ç»ƒæ•°æ®ç”Ÿæˆå®Œæˆ")
        
        # æ£€æŸ¥ç”Ÿæˆçš„æ•°æ®
        obb_data_dir = Path("data/obb_training_data")
        if not obb_data_dir.exists():
            logger.error("OBBè®­ç»ƒæ•°æ®ç›®å½•æœªç”Ÿæˆ")
            return False
        
        images_dir = obb_data_dir / "images"
        labels_dir = obb_data_dir / "labels"
        dataset_yaml = obb_data_dir / "dataset.yaml"
        
        if not all([images_dir.exists(), labels_dir.exists(), dataset_yaml.exists()]):
            logger.error("OBBè®­ç»ƒæ•°æ®ä¸å®Œæ•´")
            return False
        
        num_images = len(list(images_dir.glob("*.jpg"))) + len(list(images_dir.glob("*.png")))
        num_labels = len(list(labels_dir.glob("*.txt")))
        
        logger.info(f"ç”Ÿæˆäº† {num_images} å¼ è®­ç»ƒå›¾åƒå’Œ {num_labels} ä¸ªæ ‡æ³¨æ–‡ä»¶")
        
        return True
        
    except Exception as e:
        logger.error(f"æ•°æ®ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        return False


def train_obb_model(model_size='n', epochs=50, batch_size=8, use_pretrained=True):
    """è®­ç»ƒOBBæ¨¡å‹"""
    logger.info("=== è®­ç»ƒOBBæ¨¡å‹ ===")
    
    try:
        # æ„å»ºè®­ç»ƒå‘½ä»¤
        cmd = [
            sys.executable, 
            "detection_models/obb_train.py",
            "--data", "data/obb_training_data/dataset.yaml",
            "--model", model_size,
            "--epochs", str(epochs),
            "--batch", str(batch_size),
            "--name", f"quick_start_{model_size}"
        ]
        
        if use_pretrained:
            cmd.append("--pretrained")
        
        logger.info(f"æ‰§è¡Œè®­ç»ƒå‘½ä»¤: {' '.join(cmd)}")
        
        # è¿è¡Œè®­ç»ƒ
        result = subprocess.run(cmd, text=True, encoding='utf-8', errors='ignore')
        
        if result.returncode != 0:
            logger.error("æ¨¡å‹è®­ç»ƒå¤±è´¥")
            return False
        
        logger.info("æ¨¡å‹è®­ç»ƒå®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        return False


def test_trained_model():
    """æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹"""
    logger.info("=== æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹ ===")
    
    try:
        # æŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒç»“æœ
        runs_dir = Path("detection_models/runs/train")
        if not runs_dir.exists():
            logger.error("æœªæ‰¾åˆ°è®­ç»ƒç»“æœç›®å½•")
            return False
        
        # æ‰¾åˆ°æœ€æ–°çš„å®éªŒç›®å½•
        experiment_dirs = [d for d in runs_dir.iterdir() if d.is_dir() and d.name.startswith("quick_start")]
        if not experiment_dirs:
            logger.error("æœªæ‰¾åˆ°è®­ç»ƒå®éªŒç›®å½•")
            return False
        
        latest_exp = max(experiment_dirs, key=lambda x: x.stat().st_mtime)
        best_model = latest_exp / "weights" / "best.pt"
        
        if not best_model.exists():
            logger.error(f"æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹: {best_model}")
            return False
        
        logger.info(f"æ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹: {best_model}")
        
        # ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ£€æµ‹æµ‹è¯•
        try:
            from detection_models.obb import YOLO11OBBDetector
            
            # åˆ›å»ºæ£€æµ‹å™¨ï¼ˆä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ï¼‰
            detector = YOLO11OBBDetector(model_path=str(best_model))
            
            # æµ‹è¯•æ£€æµ‹
            test_images = list(Path("data/images").glob("*.jpg"))[:3]  # æµ‹è¯•å‰3å¼ å›¾åƒ
            if test_images:
                output_dir = "data/test_results"
                os.makedirs(output_dir, exist_ok=True)
                
                logger.info(f"ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹æµ‹è¯• {len(test_images)} å¼ å›¾åƒ...")
                
                for img_path in test_images:
                    detector.detect_single(str(img_path), output_dir)
                
                logger.info(f"æµ‹è¯•ç»“æœä¿å­˜åœ¨: {output_dir}")
            
        except Exception as e:
            logger.warning(f"æ¨¡å‹æµ‹è¯•å‡ºé”™: {str(e)}")
        
        return True
        
    except Exception as e:
        logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="YOLO11 OBB å¿«é€Ÿå¼€å§‹è„šæœ¬")
    parser.add_argument("--model", choices=['n', 's', 'm', 'l', 'x'], default='n',
                       help="æ¨¡å‹å¤§å° (é»˜è®¤: n)")
    parser.add_argument("--epochs", type=int, default=50,
                       help="è®­ç»ƒè½®æ•° (é»˜è®¤: 50)")
    parser.add_argument("--batch", type=int, default=8,
                       help="æ‰¹æ¬¡å¤§å° (é»˜è®¤: 8)")
    parser.add_argument("--no-pretrained", action="store_true",
                       help="ä¸ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹")
    parser.add_argument("--data-only", action="store_true",
                       help="ä»…ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼Œä¸è¿›è¡Œè®­ç»ƒ")
    parser.add_argument("--train-only", action="store_true",
                       help="ä»…è¿›è¡Œè®­ç»ƒï¼Œè·³è¿‡æ•°æ®ç”Ÿæˆ")
    
    args = parser.parse_args()
    
    logger.info("=== YOLO11 OBB å¿«é€Ÿå¼€å§‹ ===")
    logger.info(f"æ¨¡å‹å¤§å°: {args.model}")
    logger.info(f"è®­ç»ƒè½®æ•°: {args.epochs}")
    logger.info(f"æ‰¹æ¬¡å¤§å°: {args.batch}")
    logger.info(f"ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹: {not args.no_pretrained}")
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not check_environment():
        logger.error("ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œè¯·è§£å†³ä¸Šè¿°é—®é¢˜åé‡è¯•")
        return 1
    
    success = True
    
    # ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼ˆé™¤éæŒ‡å®šä»…è®­ç»ƒï¼‰
    if not args.train_only:
        if not generate_obb_data():
            logger.error("OBBè®­ç»ƒæ•°æ®ç”Ÿæˆå¤±è´¥")
            success = False
    
    # è®­ç»ƒæ¨¡å‹ï¼ˆé™¤éæŒ‡å®šä»…ç”Ÿæˆæ•°æ®ï¼‰
    if success and not args.data_only:
        if not train_obb_model(
            model_size=args.model,
            epochs=args.epochs,
            batch_size=args.batch,
            use_pretrained=not args.no_pretrained
        ):
            logger.error("æ¨¡å‹è®­ç»ƒå¤±è´¥")
            success = False
    
    # æµ‹è¯•æ¨¡å‹ï¼ˆä»…åœ¨å®Œæ•´æµç¨‹æˆåŠŸæ—¶ï¼‰
    if success and not args.data_only:
        test_trained_model()
    
    if success:
        logger.info("=== å¿«é€Ÿå¼€å§‹æµç¨‹å®Œæˆ ===")
        if not args.data_only:
            logger.info("ğŸ‰ æˆåŠŸä»å°‘é‡åŸå›¾ç”Ÿæˆ1000å¼ è®­ç»ƒæ•°æ®å¹¶å®Œæˆæ¨¡å‹è®­ç»ƒï¼")
            logger.info("\nğŸ“Š ç”Ÿæˆç»Ÿè®¡:")
            logger.info("- è®­ç»ƒå›¾åƒ: ~800å¼ ")
            logger.info("- éªŒè¯å›¾åƒ: ~200å¼ ") 
            logger.info("- ç±»åˆ«: part (å•ä¸€ç±»åˆ«)")
            logger.info("- æ•°æ®å¢å¼º: æ—‹è½¬ã€ç¼©æ”¾ã€äº®åº¦è°ƒæ•´ç­‰")
            logger.info("\nğŸ“ ç»“æœä½ç½®:")
            logger.info("1. è®­ç»ƒç»“æœ: detection_models/runs/train/")
            logger.info("2. åˆ†å‰²ç»“æœ: data/images/result/")
            logger.info("3. æµ‹è¯•ç»“æœ: data/test_results/")
            logger.info("4. è®­ç»ƒæ•°æ®: data/obb_training_data/")
            logger.info("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
            logger.info("- æŸ¥çœ‹è®­ç»ƒæ›²çº¿è¯„ä¼°æ¨¡å‹æ€§èƒ½")
            logger.info("- ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ£€æµ‹")
            logger.info("- æ ¹æ®ç»“æœè°ƒæ•´å‚æ•°é‡æ–°è®­ç»ƒ")
        else:
            logger.info("ğŸ‰ æˆåŠŸä»å°‘é‡åŸå›¾ç”Ÿæˆ1000å¼ OBBè®­ç»ƒæ•°æ®ï¼")
            logger.info("\nğŸ“Š ç”Ÿæˆç»Ÿè®¡:")
            logger.info("- è®­ç»ƒæ•°æ®: data/obb_training_data/train/ (~800å¼ )")
            logger.info("- éªŒè¯æ•°æ®: data/obb_training_data/val/ (~200å¼ )")
            logger.info("- åˆ†å‰²ç»“æœ: data/images/result/")
            logger.info("- æ•°æ®é…ç½®: data/obb_training_data/dataset.yaml")
            logger.info("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
            logger.info("è¿è¡Œè®­ç»ƒ: cd detection_models && python obb_train.py --data ../data/obb_training_data/dataset.yaml --pretrained")
        return 0
    else:
        logger.error("å¿«é€Ÿå¼€å§‹æµç¨‹å¤±è´¥")
        return 1


if __name__ == "__main__":
    exit(main()) 